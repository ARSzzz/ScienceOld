# 深度学习基本概率

## 线性整流函数 Rectified Linear Unit, ReLU

线性整流函数,又称**修正线性单元**, 是一种人工神经网络中常用的激活函数（activation function），通常指代以**斜坡函数**及其变种为代表的非线性函数。

- 斜坡函数

$$P(x)=\max(0,x)$$

## Dropout

dropout是指在深度学习网络的训练过程中，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃。注意是暂时，对于随机梯度下降来说，由于是随机丢弃，故而每一个mini-batch都在训练不同的网络。

dropout是CNN中防止过拟合提高效果的一个大杀器，但对于其为何有效，却众说纷纭。
