# 组合方法 Ensemble method

**组合**（`ensemble`）或**分类器组合**（`classifier combination`）方法，指通过聚集多个分类器的预测来提高分类准确率。[^组合]

分类器组合由训练数据构建一组**基分类器**（`base classifier`），然后通过对每个基分类器的预测结果进行投票来确定最终分类。

为何能改善分类器的性能？略。

组合分类器的性能优于单个分类器时必须满足两个必要条件：

1. 基分类器之间必须是相互独立的。
2. 基分类器的性能应当好于随机猜测分类器。

构建组合分类器的方法：

1. 通过处理**训练数据集**

    - 装袋（`Bagging`）
    - 提升（`Boosting`）

2. 通过处理**输入特征**

    - 随机森林（`Random forest`）

3. 通过处理**类标号**

    - 错误-纠正输出编码（`Error-correcting output coding`）

4. 通过处理**学习算法**

## 装袋 Bagging

**装袋**又称**自助聚类**（`Bootstrap aggregating`），是一种根据均匀概率从数据集中有放回地重复抽样技术。[^自助聚类]

由于抽样过程是有放回的，因此一些样本可能在同一个训练数据集中出现多次，而另一些样本则可能被忽略。一般地，自助样本包 $D_i$ 大约包含 `63%` 的原训练数据。

- **参数**
> ($D$): 样本总集
> ($k$): 自助样本集的数目

- **流程**
> for $i$ 从 1 到 $k$:
> ⋯⋯ 从 $D$ 中根据均匀概率生成一个样本量为 $N$ 的自助样本集 $D_i$
> ⋯⋯ 在 $D_i$ 上训练一个基分类器 $C_i$
>
> 最终分类器:
> $C^*(x)=argmax_y\sum_i\delta(\cdot)$
> $
> \delta(\cdot)=\left\{
> \begin{aligned}
> 1 &  & C_i(x)=y \\
> 0 &  & C_i(x)!=y
> \end{aligned}
> \right.
> $

## 提升 Boosting

提升（Boosting）。

### Adaboosting

略

## GBDT

略。

[^组合]:组合相关：
[wikipedia: Ensemble averaging](https://en.wikipedia.org/wiki/Ensemble_averaging_(machine_learning))
[sklearn: Ensemble methods](http://scikit-learn.org/stable/modules/ensemble.html)

[^自助聚类]: 自助聚类相关:
[wikipedia: Bootstrap aggregating](https://en.wikipedia.org/wiki/Bootstrap_aggregating),
[sklearn.ensemble.BaggingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)
