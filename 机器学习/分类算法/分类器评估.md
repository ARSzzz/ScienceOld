<!-- @import "../../引用/my-style.less" -->

# 分类器评估 Classfier assessment

## 一、交叉验证法 Cross validation

### 1.1 概述 Overview

在有监督的机器学习即监督学习（Supervised learning）中，样本集常被分成 2 个或 3 个，即（训练集，测试集）或（训练集，验证集，测试集）。

- **训练集（Train set）**：用于学习的样本集，也就是拟合模型中的参数。
- **验证集（Validation set）**：用于调优模型中的参数。
- **测试集（Test set）**：用于评估一个已完成模型的性能。

验证集的用途示例有：选择神经网络中隐藏层的数量。

**交叉验证**（Cross Validation），也称**循环估计**（Rotation Estimation），是指一系列相似的方法，其均将样本集划分为若干独立的数据集，并用这些数据集中的一些用来拟合模型的参数，另一些用来测试模型的性能。

交叉验证法是由 Seymour geisser 最先提出的。*验证模型的性能，也即计算模型的泛化误差的无偏估计*。交叉验证法的常见形式有：

- `Non-exhaustive cross-validation`
  - 保持方法（Holdout method）
  - K 折交叉验证（K-fold cross-validation）
  - 随机二次抽样（Repeated random sub-sampling validation）

- `Exhaustive cross-validation`
  - 留一交叉验证（Leave-one-out cross-validation）
  - `Leave-p-out cross-validation`

`Exhaustive cross-validation`：该方法会穷尽所有的划分可能。
`Non-exhaustive cross-validation`：该方法不会穷尽所有的划分可能。

### 1.2 保持方法 Holdout method

将样本集随机划分成两个不相交的子集，分别称为**训练集**和**测试集**。其划分比例通常根据专家来定义，而且测试集通常要比训练集小。在训练集上拟合模型的参数，在测试集上评估模型的性能。分类器的性能根据模型在测试集上的性能来估计。

保持方法的局限性：

- 用于训练的数据集减少，最终的模型不如使用所有数据集建立的模型好。
- 模型性能高度依赖于训练集和验证集的构成。
- 训练集和验证集不是相互独立的，因为它们来自同一个数据集。

### 1.3 重复随机二次抽样验证法 Repeated random sub-sampling validation

本方法也称为**蒙特卡罗交叉验证法**（Monte Carlo cross-validation）。是指重复地将样本集随机划分为**训练集**和**验证集**，在训练集上拟合模型的参数，在验证集上评估模型的性能。最终的结果是所有评估结果的均值。

总的来说，本方法是多次重复**保持方法**来改进对分类器性能的估计。

### 1.4 K 折交叉验证 K-fold cross-validation

将样本集随机分为大小相同的 $k$ 个子集。选择其中一个子集作为**验证集**，其余的 $k-1$ 个子集全部作为**训练集**。在训练集上拟合模型的参数，在验证集上评估模型的性能。上述过程重复 $k$ 次，使每个子集作为验证集恰好一次。最终的结果是 $k$ 次评估结果的均值。

### 1.5 留一方法 Leave one out cross-validation

当样本集中的样本数 $N$ 等于划分后的子集数 $k$ 时的 $k$ 折交叉验证法就是留一方法。因此，在该方法中的每个验证集只有一个样本。

### 1.6 Leave-p-out cross-validation

该方法使用大小为 $N$ 的样本集中 $p$ 个样本作为测试集，其余的 $N-p$ 个样本均作为训练集。在训练集上拟合模型的参数，在验证集上评估模型的性能。重复上述过程 $\binom{N}{p}$ 次，正好穷尽该 $p$ 个样本组成的测试集的所有可能性。

## 二、评价一个分类模型 Assess a classifier

### 2.1 概述 Overview

对于二分类问题，样本对应的类只有两种，称为**阳性**（Positive）和**阴性**(Negative)。一般用 `Recall`，`Precision`，`F-score` 的概念来评估模型的性能。对于二分类问题，其**混淆矩阵**（Confusion matrix,）如下：

|                                    | `Condition positive`                        | `Condition negative`                       |
| ---------------------------------- | ------------------------------------------- | ------------------------------------------ |
| **`Predicted condition positive`** | `True positive` [$\surd$] `Power`           | `False positive` [$\times$] `Type I error` |
| **`Predicted condition negative`** | `False negative` [$\times$] `Type II error` | `True negative` [$\surd$]                  |

**精确率 Precision**：又称 `Positive predictive value`，是判断为阳性的样本中事实为阳性的样本的比例。其定义如下：
$$\text{Precision}=\frac{\text{TP}}{\text{TP+FP}}\tag{1}$$

**召回率 Recall**：又称**敏感度**（Sensitivity），或 `True positive rate`，`probability of detection`。其定义如下：
$$\text{Recall} = \frac{\text{TP}}{\text{TP+FN}}\tag{2}$$

**Specificity**：又称 `true negative rate`。它的值定义如下：
$$\text{TNR}=\frac{\text{TN}}{\text{TN+FP}}\tag{3}$$

**准确率 Accuracy**：判断正确的样本占所有样本的比率，其值如下：
$$\text{Accuracy}=\frac{\text{TP+TN}}{\text{N}}, \quad \text{N}=\text{TP+TN+FP+FN}\tag{4}$$

**F 值 F-score**：又称 `F-measure`，是对测试的准确性的测量，定义如式 $(5)$。当参数 $\beta=1$ 时的 `F-score` 称为 $F_1$ 值，如式 $(6)$。
$$F_\beta = (1 + \beta^2) \cdot \frac {\text{precision} \cdot \text{recall}} {\beta^2 \cdot \text{precision} + \text{recall}}\tag{5}
$$

$$F_1=2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision+Recall}}\tag{6}
$$
